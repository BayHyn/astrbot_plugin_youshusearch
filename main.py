import asyncio
import aiohttp
import json
import time
import random
import re
from typing import Dict, List, Optional
from urllib.parse import urljoin, quote

from astrbot.api.event import filter, AstrMessageEvent, MessageEventResult
from astrbot.api.star import Context, Star, register
import astrbot.api.message_components as Comp
from astrbot.api import logger

@register(
    "astrbot_plugin_youshusearch",  # æ’ä»¶ID
    "Foolllll",                    # ä½œè€…å
    "ä¼˜ä¹¦æœç´¢æ’ä»¶",                  # æ’ä»¶æ˜¾ç¤ºåç§°
    "1.1",                         # ç‰ˆæœ¬å·
    "https://github.com/Foolllll-J/astrbot_plugin_youshusearch", # æ’ä»¶ä»“åº“åœ°å€
)
class YoushuSearchPlugin(Star):
    def __init__(self, context: Context, config=None):
        super().__init__(context)
        self.base_api_url = "https://www.ypshuo.com/"
        self.search_api_endpoint = "api/novel/search"
        
        self.headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36",
            "Accept": "application/json, text/plain, */*",
            "Accept-Language": "zh-CN,zh;q=0.9,en-US;q=0.8,en;q=0.7",
            "Accept-Encoding": "gzip, deflate, br",
            "Connection": "keep-alive",
        }

    async def _perform_search(self, session: aiohttp.ClientSession, keyword: str, page: int = 1) -> Optional[List[Dict]]:
        """ç›´æ¥è°ƒç”¨åç«¯æœç´¢APIå¹¶è§£æJSONç»“æœ"""
        search_api_url = urljoin(self.base_api_url, self.search_api_endpoint)
        
        params = {
            "keyword": keyword,
            "page": str(page)
        }
        
        try:
            async with session.get(search_api_url, params=params, headers=self.headers, timeout=20) as response:
                response.raise_for_status()

                json_content = await response.json()
                
                logger.info(f"æœç´¢ '{keyword}' APIè°ƒç”¨æˆåŠŸã€‚JSONå†…å®¹é¢„è§ˆ: {json.dumps(json_content, ensure_ascii=False)[:500]}...")

                if json_content.get("code") == "00" and json_content.get("data"):
                    return json_content["data"].get("data", [])
                else:
                    logger.warning(f"æœç´¢APIè¿”å›éæˆåŠŸä»£ç æˆ–æ— æ•°æ®: {json_content}")
                    return None

        except aiohttp.ClientError as e:
            logger.error(f"âŒ è®¿é—®æœç´¢APIå¤±è´¥: ç½‘ç»œæˆ–HTTPé”™è¯¯ - {e}")
            raise
        except asyncio.TimeoutError:
            logger.error(f"âŒ è®¿é—®æœç´¢APIè¶…æ—¶ã€‚")
            raise
        except json.JSONDecodeError as e:
            logger.error(f"âŒ è§£æAPIå“åº”JSONå¤±è´¥: {e}. å“åº”å†…å®¹: {await response.text()}")
            raise
        except Exception as e:
            logger.error(f"âŒ æ‰§è¡Œæœç´¢APIæ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
            raise

    async def _get_latest_novel_id(self, session: aiohttp.ClientSession) -> Optional[int]:
        """è·å–ä¼˜ä¹¦ç½‘æœ€æ–°çš„å°è¯´ID"""
        url = "https://www.ypshuo.com/"
        try:
            async with session.get(url, headers=self.headers, timeout=10) as response:
                response.raise_for_status()
                html_content = await response.text()
                
                matches = re.findall(r'href="/novel/(\d+)\.html"', html_content)
                
                if matches:
                    latest_id = max([int(id) for id in matches])
                    logger.info(f"âœ… æˆåŠŸè·å–åˆ°æœ€æ–°çš„å°è¯´ID: {latest_id}")
                    return latest_id
                else:
                    logger.warning("âŒ æœªèƒ½åœ¨ä¸»é¡µHTMLä¸­æ‰¾åˆ°æœ€æ–°çš„å°è¯´IDã€‚")
                    return None
        except aiohttp.ClientError as e:
            logger.error(f"âŒ è®¿é—®ä¸»é¡µå¤±è´¥: ç½‘ç»œæˆ–HTTPé”™è¯¯ - {e}")
            return None
        except Exception as e:
            logger.error(f"âŒ è·å–æœ€æ–°å°è¯´IDæ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
            return None

    async def _get_novel_details_from_html(self, html_content: str, novel_id: str) -> Dict:
        """
        ä»HTMLå“åº”ä¸­æå–å°è¯´è¯¦ç»†ä¿¡æ¯çš„è¾…åŠ©å‡½æ•°ï¼Œä½¿ç”¨æ›´å¥å£®çš„DOMè§£æã€‚
        å·²ä¿®å¤å°é¢å›¾ç‰‡è·å–é€»è¾‘ã€‚
        """
        novel_info = {}

        try:
            # 1. ä¼˜å…ˆä»OGPå…ƒæ ‡ç­¾ä¸­æå–å°é¢å›¾ç‰‡URL
            og_image_match = re.search(r'<meta[^>]*?name="og:image"[^>]*?content="(.*?)"', html_content)
            if og_image_match:
                image_url = og_image_match.group(1)
                # ç¡®ä¿URLæ˜¯å®Œæ•´çš„
                if image_url.startswith('//'):
                    image_url = 'https:' + image_url
                elif image_url.startswith('/'):
                    image_url = urljoin(self.base_api_url, image_url)
                novel_info['image_url'] = image_url
                logger.info(f"æå–åˆ°çš„å°é¢URL (ä»OGPæ ‡ç­¾): {image_url}")
            else:
                # 2. å¦‚æœOGPæ ‡ç­¾ä¸å­˜åœ¨ï¼Œå†å›é€€åˆ°åŸæ¥çš„æ­£åˆ™åŒ¹é…æ–¹æ³•
                image_match = re.search(r'<img src="(.*?)"[^>]*?class="book-img"', html_content)
                if image_match:
                    image_url = image_match.group(1)
                    if image_url.startswith('/'):
                        image_url = urljoin(self.base_api_url, image_url)
                    novel_info['image_url'] = image_url
                    logger.info(f"æå–åˆ°çš„å°é¢URL (ä»<img>æ ‡ç­¾): {image_url}")
                else:
                    novel_info['image_url'] = None
                    logger.warning("æœªèƒ½ä»é¡µé¢ä¸­æå–åˆ°å°é¢å›¾ç‰‡URLã€‚")


            # æå–ä¹¦å
            name_match = re.search(r'<h1 class="book-name".*?>(.*?)</h1>', html_content, re.DOTALL)
            novel_info['novel_name'] = name_match.group(1).strip() if name_match else 'æ— '
            
            # æå–ä½œè€…å
            author_match = re.search(r'ä½œè€…ï¼š<span class="text-red-500".*?>(.*?)</span>', html_content)
            novel_info['author_name'] = author_match.group(1).strip() if author_match else 'æ— '

            # æå–å­—æ•°
            word_count_match = re.search(r'å­—æ•°ï¼š(.*?)ä¸‡å­—', html_content)
            if word_count_match:
                try:
                    word_str = word_count_match.group(1).strip().replace(',', '')
                    novel_info['word_number'] = float(word_str) * 10000
                except (ValueError, TypeError):
                    novel_info['word_number'] = None
            else:
                novel_info['word_number'] = None
            
            # æå–è¯„åˆ†å’Œè¯„åˆ†äººæ•°
            score_data_matches = re.findall(r'<div class="item"[^>]*?>\s*<p class="score"[^>]*?>\s*(.*?)\s*</p>\s*<p[^>]*?>(.*?)</p>\s*</div>', html_content, re.DOTALL)
            
            novel_info['score'] = 'æ— '
            novel_info['scorer'] = 'æ— '

            for value, label in score_data_matches:
                if label.strip() == 'è¯„åˆ†':
                    novel_info['score'] = value.strip()
                elif label.strip() == 'è¯„åˆ†äººæ•°':
                    novel_info['scorer'] = value.strip()
            
            # æå–çŠ¶æ€
            status_match = re.search(r'çŠ¶æ€ï¼š\s*(.*?)\s*<', html_content)
            novel_info['status'] = status_match.group(1).strip() if status_match else 'æ— '

            # æå–æ›´æ–°æ—¶é—´
            update_time_match = re.search(r'æ›´æ–°æ—¶é—´ï¼š\s*(.*?)\s*</div>', html_content)
            novel_info['update_time_str'] = update_time_match.group(1).strip() if update_time_match else 'æ— '
            
            reviews = []
            review_item_regex = re.compile(r'<div class="item"[^>]*?>.*?<div class="discuss-content"[^>]*?>.*?<span class="content-inner-details"[^>]*?>(.*?)</span>.*?</div>.*?</div>.*?<div class="novel-rate"[^>]*?><div role="slider" aria-valuenow="([^"]+)"', re.DOTALL)
            all_reviews = review_item_regex.findall(html_content)
            
            for review_data in all_reviews[:3]: 
                content_block, rating = review_data
                
                content = re.sub(r'<[^>]+>', '', content_block)
                content = re.sub(r'[\r\n\t]+', '', content).strip()
                
                if content:
                    reviews.append({
                        'content': content,
                        'rating': rating
                    })

            novel_info['reviews'] = reviews
            
            # æå–ç®€ä»‹
            synopsis_match = re.search(r'<div style="white-space:pre-wrap;"[^>]*?>(.*?)</div>', html_content, re.DOTALL)
            synopsis_content = synopsis_match.group(1).strip() if synopsis_match else 'æ— '
            novel_info['synopsis'] = synopsis_content
            
            # æå–é“¾æ¥
            link_match = re.search(r'<a href="(http.*?)".*?rel="nofollow".*?>', html_content)
            novel_info['link'] = link_match.group(1).strip() if link_match else 'æ— '

            return novel_info
            
        except Exception as e:
            logger.error(f"âŒ DOMè§£æå¤±è´¥ã€‚é”™è¯¯: {e}")
            return {}

    @filter.command("ys") # å®šä¹‰æŒ‡ä»¤ /ys ä¹¦å
    async def youshu_search_command(self, event: AstrMessageEvent, book_name: str):
        """
        æœç´¢æœ‰ä¹¦ç½‘ä¸Šçš„ä¹¦ç±ä¿¡æ¯ã€‚
        ç”¨æ³•: /ys <ä¹¦å>
        ç¤ºä¾‹: /ys è¯¡ç§˜ä¹‹ä¸»
        """
        if not book_name:
            yield event.plain_result("âŒ è¯·æä¾›ä¹¦åè¿›è¡Œæœç´¢ã€‚")
            return

        try:
            async with aiohttp.ClientSession() as session:
                search_results = await self._perform_search(session, book_name)

                if search_results:
                    locked_book = None
                    for book in search_results:
                        if book.get('novel_name', '').lower().strip() == book_name.lower().strip():
                            locked_book = book
                            break
                    
                    if locked_book:
                        novel_id = locked_book.get('id')
                        
                        if novel_id:
                            logger.info(f"ğŸ” é”å®šç²¾ç¡®ä¹¦ç±ï¼ŒID: {novel_id}")
                            novel_url = f"https://www.ypshuo.com/novel/{novel_id}.html"
                            
                            try:
                                async with session.get(novel_url, headers=self.headers, timeout=10) as response:
                                    response.raise_for_status()
                                    html_content = await response.text()
                                
                                novel_info = await self._get_novel_details_from_html(html_content, str(novel_id))
                                
                                if novel_info and novel_info.get('novel_name'):
                                    message_text = f"---ã€{novel_info.get('novel_name', 'æ— ')}ã€‘è¯¦ç»†ä¿¡æ¯ ---\n"
                                    message_text += f"ä½œè€…: {novel_info.get('author_name', 'æ— ')}\n"
                                    
                                    word_number = novel_info.get('word_number')
                                    if word_number is not None and isinstance(word_number, (int, float)):
                                        message_text += f"å­—æ•°: {word_number / 10000:.2f}ä¸‡å­—\n"
                                    else:
                                        message_text += f"å­—æ•°: æ— \n"

                                    score = novel_info.get('score', 'æ— ')
                                    scorer = novel_info.get('scorer', 'æ— ')
                                    message_text += f"è¯„åˆ†: {score} ({scorer}äººè¯„åˆ†)\n"

                                    message_text += f"çŠ¶æ€: {novel_info.get('status', 'æ— ')}\n"
                                    message_text += f"æ›´æ–°: {novel_info.get('update_time_str', 'æ— ')}\n"

                                    synopsis = novel_info.get('synopsis', 'æ— ')
                                    message_text += f"ç®€ä»‹: {synopsis[:200]}...\n"

                                    message_text += f"ğŸ”— é“¾æ¥: {novel_info.get('link', novel_url)}\n"

                                    reviews = novel_info.get('reviews', [])
                                    if reviews:
                                        message_text += "\n--- ğŸ“ æœ€æ–°ä¹¦è¯„ ---\n"
                                        for i, review in enumerate(reviews):
                                            message_text += f"ä¹¦è¯„{i+1} ({review.get('rating', 'æ— ')}åˆ†): {review.get('content', 'æ— ')}\n"
                                    
                                    chain = []
                                    if novel_info.get('image_url'):
                                        chain.append(Comp.Image.fromURL(novel_info['image_url']))
                                    chain.append(Comp.Plain(message_text))

                                    yield event.chain_result(chain)
                                    return
                            
                            except aiohttp.ClientResponseError as e:
                                logger.error(f"âŒ è®¿é—®é¡µé¢ {novel_url} å¤±è´¥ï¼ŒHTTPçŠ¶æ€ç : {e.status}")
                                yield event.plain_result(f"âŒ è®¿é—®ä¹¦ç±è¯¦æƒ…é¡µå¤±è´¥ã€‚è¯·å°è¯•ä½¿ç”¨`/testys {novel_id}`ã€‚")
                            except Exception as e:
                                logger.error(f"è§£æä¹¦ç±è¯¦æƒ…é¡µå¤±è´¥: {e}")
                                yield event.plain_result(f"âŒ è§£æä¹¦ç±è¯¦æƒ…é¡µæ—¶å‘ç”Ÿé”™è¯¯: {str(e)}ã€‚")

                    else:
                        all_titles = "\n".join([f"â€¢ {b.get('novel_name', 'æ— ')}" for b in search_results])
                        yield event.plain_result(f"ä»¥ä¸‹æ˜¯å…³äºã€{book_name}ã€‘çš„æœç´¢ç»“æœ:\n{all_titles}\n\nğŸ’¡ å¦‚æœæƒ³æŸ¥çœ‹æ›´å¤šï¼Œè¯·å°è¯•æ›´ç²¾ç¡®çš„ä¹¦åã€‚")

                else:
                    yield event.plain_result(f"ğŸ˜¢ æœªæ‰¾åˆ°å…³äºã€{book_name}ã€‘çš„ä¹¦ç±ä¿¡æ¯ã€‚")

        except Exception as e:
            logger.error(f"æœç´¢ä¹¦ç±å¤±è´¥: {e}")
            yield event.plain_result(f"âŒ æœç´¢ä¹¦ç±æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")

    @filter.command("testys")
    async def testys_command(self, event: AstrMessageEvent, novel_id: str = "1"):
        """
        æµ‹è¯•ç”¨æŒ‡ä»¤ï¼Œæ ¹æ®æŒ‡å®šIDè§£æå°è¯´ä¿¡æ¯ã€‚
        ç”¨æ³•: /testys [ä¹¦ç›®ID]
        ç¤ºä¾‹: /testys 45830
        """
        yield event.plain_result(f"ğŸ§ª æ­£åœ¨æµ‹è¯•è§£æä¹¦ç›®ID: ã€{novel_id}ã€‘ï¼Œè¯·ç¨å€™...")

        try:
            async with aiohttp.ClientSession() as session:
                novel_url = f"https://www.ypshuo.com/novel/{novel_id}.html"
                try:
                    async with session.get(novel_url, headers=self.headers, timeout=10) as response:
                        response.raise_for_status()
                        html_content = await response.text()
                except aiohttp.ClientResponseError as e:
                    yield event.plain_result(f"âŒ è®¿é—®é¡µé¢ {novel_url} å¤±è´¥ï¼ŒHTTPçŠ¶æ€ç : {e.status}")
                    return

                novel_info = await self._get_novel_details_from_html(html_content, novel_id)

                if not novel_info or not novel_info.get('novel_name'):
                    yield event.plain_result(f"ğŸ˜¢ æ— æ³•ä»é¡µé¢ {novel_id} æå–æœ‰æ•ˆä¿¡æ¯ï¼Œè¯·æ£€æŸ¥IDæˆ–é‡è¯•ã€‚")
                    return

                # æ ¼å¼åŒ–å¹¶è¿”å›ä¿¡æ¯
                message_text = f"--- âœ… ã€{novel_info.get('novel_name', 'æ— ')}ã€‘ (æµ‹è¯•è§£æ) ---\n"
                message_text += f"âœï¸ ä½œè€…: {novel_info.get('author_name', 'æ— ')}\n"
                
                word_number = novel_info.get('word_number')
                if word_number is not None and isinstance(word_number, (int, float)):
                    message_text += f"å­—æ•°: {word_number / 10000:.2f}ä¸‡å­—\n"
                else:
                    message_text += f"å­—æ•°: æ— \n"

                score = novel_info.get('score', 'æ— ')
                scorer = novel_info.get('scorer', 'æ— ')
                message_text += f"è¯„åˆ†: {score} ({scorer}äººè¯„åˆ†)\n"

                message_text += f"çŠ¶æ€: {novel_info.get('status', 'æ— ')}\n"
                message_text += f"æ›´æ–°: {novel_info.get('update_time_str', 'æ— ')}\n"

                synopsis = novel_info.get('synopsis', 'æ— ')
                message_text += f"ç®€ä»‹: {synopsis[:200]}...\n"

                message_text += f"ğŸ”— é“¾æ¥: {novel_info.get('link', novel_url)}\n"

                reviews = novel_info.get('reviews', [])
                if reviews:
                    message_text += "\n--- ğŸ“ æœ€æ–°ä¹¦è¯„ ---\n"
                    for i, review in enumerate(reviews):
                        message_text += f"ä¹¦è¯„{i+1} ({review.get('rating', 'æ— ')}åˆ†): {review.get('content', 'æ— ')}\n"
                
                chain = []
                if novel_info.get('image_url'):
                    chain.append(Comp.Image.fromURL(novel_info['image_url']))
                chain.append(Comp.Plain(message_text))

                yield event.chain_result(chain)

        except Exception as e:
            logger.error(f"æµ‹è¯•è§£æå°è¯´å¤±è´¥: {e}")
            yield event.plain_result(f"âŒ æµ‹è¯•è§£ææ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")

    @filter.command("éšæœºå°è¯´")
    async def youshu_random_command(self, event: AstrMessageEvent):
        """
        éšæœºè·å–ä¸€æœ¬ä¼˜ä¹¦ç½‘ä¸Šçš„å°è¯´ä¿¡æ¯ã€‚
        ç”¨æ³•: /éšæœºå°è¯´
        """
        
        max_retries = 5
        for attempt in range(max_retries):
            try:
                async with aiohttp.ClientSession() as session:
                    latest_id = await self._get_latest_novel_id(session)
                    if not latest_id:
                        yield event.plain_result("âŒ æŠ±æ­‰ï¼Œæœªèƒ½è·å–åˆ°æœ€æ–°çš„å°è¯´IDï¼Œæ— æ³•è¿›è¡Œéšæœºæœç´¢ã€‚")
                        return
                    
                    random_id = random.randint(1, latest_id)
                    novel_url = f"https://www.ypshuo.com/novel/{random_id}.html"
                    logger.info(f"ç¬¬ {attempt + 1} æ¬¡å°è¯•éšæœºID: {random_id}")

                    try:
                        async with session.get(novel_url, headers=self.headers, timeout=10) as response:
                            response.raise_for_status()
                            html_content = await response.text()
                    except aiohttp.ClientResponseError as e:
                        if e.status == 404:
                            logger.warning(f"é¡µé¢ {novel_url} ä¸å­˜åœ¨ï¼Œæ­£åœ¨é‡è¯•...")
                            continue
                        else:
                            raise

                    novel_info = await self._get_novel_details_from_html(html_content, str(random_id))

                    if not novel_info or not novel_info.get('novel_name'):
                        logger.warning(f"æ— æ³•ä»é¡µé¢ {random_id} æå–æœ‰æ•ˆä¿¡æ¯ï¼Œæ­£åœ¨é‡è¯•...")
                        continue

                    # æ ¼å¼åŒ–å¹¶è¿”å›ä¿¡æ¯
                    message_text = f"---ã€{novel_info.get('novel_name', 'æ— ')}ã€‘---\n"
                    
                    author_name = novel_info.get('author_name', 'æ— ')
                    if not author_name:
                        author_name = 'æ— '
                    message_text += f"ä½œè€…: {author_name}\n"
                    
                    word_number = novel_info.get('word_number')
                    if word_number is not None and isinstance(word_number, (int, float)):
                        message_text += f"å­—æ•°: {word_number / 10000:.2f}ä¸‡å­—\n"
                    else:
                        message_text += f"å­—æ•°: æ— \n"

                    score = novel_info.get('score', 'æ— ')
                    scorer = novel_info.get('scorer', 'æ— ')
                    message_text += f"è¯„åˆ†: {score} ({scorer}äººè¯„åˆ†)\n"

                    message_text += f"çŠ¶æ€: {novel_info.get('status', 'æ— ')}\n"
                    message_text += f"æ›´æ–°: {novel_info.get('update_time_str', 'æ— ')}\n"

                    synopsis = novel_info.get('synopsis', 'æ— ')
                    message_text += f"ç®€ä»‹: {synopsis[:200]}...\n"

                    message_text += f"ğŸ”— é“¾æ¥: {novel_info.get('link', novel_url)}\n"

                    reviews = novel_info.get('reviews', [])
                    if reviews:
                        message_text += "\n--- ğŸ“ æœ€æ–°ä¹¦è¯„ ---\n"
                        for i, review in enumerate(reviews):
                            message_text += f"ä¹¦è¯„{i+1} ({review.get('rating', 'æ— ')}åˆ†): {review.get('content', 'æ— ')}\n"
                    
                    chain = []
                    if novel_info.get('image_url'):
                        chain.append(Comp.Image.fromURL(novel_info['image_url']))
                    chain.append(Comp.Plain(message_text))

                    yield event.chain_result(chain)
                    return

            except Exception as e:
                logger.error(f"éšæœºè·å–å°è¯´å¤±è´¥: {e}")
                yield event.plain_result(f"âŒ éšæœºè·å–å°è¯´æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
                return
        
        yield event.plain_result("ğŸ˜¢ æŠ±æ­‰ï¼Œå¤šæ¬¡å°è¯•åä»æœªæ‰¾åˆ°æœ‰æ•ˆçš„å°è¯´é¡µé¢ã€‚è¯·ç¨åå†è¯•ã€‚")

    async def terminate(self):
        """æ’ä»¶é”€æ¯æ—¶çš„æ¸…ç†å·¥ä½œ"""
        logger.info("ä¼˜ä¹¦æœç´¢æ’ä»¶å·²å¸è½½")
